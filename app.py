#!/usr/bin/env python3
# app.py â€” HuggingFace Spaces App for HAZE
#
# Full-featured HAZE interface using Gradio.
# Uses ALL emergent processes: CLOUD, trauma, subjectivity, cleanup, etc.
#
# NO SEED FROM PROMPT â€” HAZE speaks from its internal field.
#
# Usage:
#   pip install gradio
#   python app.py
#
# For HuggingFace Spaces:
#   1. Create a Space with Gradio SDK
#   2. Upload all files from this repo
#   3. The Space will auto-detect app.py
#
# Co-authored by Claude (GitHub Copilot Coding Agent), January 2026

import asyncio
import sys
from pathlib import Path
from typing import List, Tuple, Optional

# Add paths
sys.path.insert(0, str(Path(__file__).parent))
sys.path.insert(0, str(Path(__file__).parent / "haze"))
sys.path.insert(0, str(Path(__file__).parent / "cloud"))

# Import HAZE components
try:
    from haze.async_haze import AsyncHazeField, HazeResponse
except ImportError:
    # Fallback for direct execution
    from async_haze import AsyncHazeField, HazeResponse

# Import CLOUD
try:
    from cloud import Cloud, AsyncCloud, CloudResponse, CHAMBER_NAMES
    HAS_CLOUD = True
    print("[app] CLOUD module loaded (~181K params)")
except ImportError as e:
    print(f"[app] CLOUD not available: {e}")
    HAS_CLOUD = False
    Cloud = None
    AsyncCloud = None

# Import DSL
try:
    from haze.dsl import AriannaDSL, FieldState
    HAS_DSL = True
    print("[app] DSL module loaded (Arianna Method operators)")
except ImportError:
    HAS_DSL = False
    AriannaDSL = None


# ============================================================================
# HAZE SESSION WITH FULL CLOUD INTEGRATION
# ============================================================================

class HazeSession:
    """
    Manages a HAZE conversation session with full CLOUD integration.
    
    Architecture:
        1. CLOUD (~181K params) â€” pre-semantic emotion detection
           - 6 chambers: FEAR, LOVE, RAGE, VOID, FLOW, COMPLEX
           - Cross-fire stabilization
           - Meta-observer for secondary emotion
        
        2. HAZE â€” async field generation
           - Subjectivity module (NO SEED FROM PROMPT)
           - Trauma module (identity anchoring)
           - Expert mixture (structural/semantic/creative/precise)
           - Co-occurrence field (pattern resonance)
        
        3. DSL â€” Arianna Method operators
           - prophecy_debt tracking
           - Emotional topology (pain, tension, dissonance)
    """
    
    def __init__(self):
        self.haze: Optional[AsyncHazeField] = None
        self.cloud: Optional[Cloud] = None
        self.dsl: Optional[AriannaDSL] = None
        self.history: List[Tuple[str, str]] = []
        self.corpus_path = Path(__file__).parent / "haze" / "text.txt"
        self._initialized = False
        self._cloud_responses: List[CloudResponse] = []
    
    async def initialize(self):
        """Initialize HAZE field and CLOUD."""
        if self._initialized:
            return
        
        # Find corpus
        if not self.corpus_path.exists():
            alt_paths = [
                Path(__file__).parent / "text.txt",
                Path("haze/text.txt"),
                Path("text.txt"),
            ]
            for p in alt_paths:
                if p.exists():
                    self.corpus_path = p
                    break
        
        if not self.corpus_path.exists():
            raise FileNotFoundError(f"Corpus not found: {self.corpus_path}")
        
        print(f"[app] Loading corpus from {self.corpus_path}")
        
        # Initialize HAZE
        self.haze = AsyncHazeField(str(self.corpus_path))
        await self.haze.__aenter__()
        print(f"[app] HAZE initialized")
        
        # Initialize CLOUD with full 181K architecture
        if HAS_CLOUD:
            try:
                models_path = Path(__file__).parent / "cloud" / "models"
                if models_path.exists():
                    self.cloud = Cloud.load(models_path)
                    print(f"[app] CLOUD loaded from {models_path}")
                else:
                    self.cloud = Cloud.random_init(seed=42)
                    print(f"[app] CLOUD initialized with random weights")
                print(f"[app] CLOUD params: {self.cloud.param_count():,}")
            except Exception as e:
                print(f"[app] CLOUD init failed: {e}")
                self.cloud = None
        
        # Initialize DSL
        if HAS_DSL:
            self.dsl = AriannaDSL()
            print(f"[app] DSL initialized (Arianna Method operators)")
        
        self._initialized = True
        print(f"[app] Session ready!")
    
    async def respond(self, user_input: str) -> Tuple[str, dict]:
        """
        Generate HAZE response with full CLOUD integration.
        
        Pipeline:
            1. CLOUD ping â†’ detect pre-semantic emotion
            2. Update DSL state with CLOUD output
            3. HAZE respond â†’ generate from internal field
            4. Track prophecy debt
        
        Returns:
            (response_text, metadata)
        """
        if not self._initialized:
            await self.initialize()
        
        # ===== 1. CLOUD PING =====
        cloud_data = {}
        cloud_response = None
        
        if self.cloud:
            try:
                cloud_response = await self.cloud.ping(user_input)
                self._cloud_responses.append(cloud_response)
                
                cloud_data = {
                    "primary": cloud_response.primary,
                    "secondary": cloud_response.secondary,
                    "chambers": cloud_response.chamber_activations,
                    "iterations": cloud_response.iterations,
                    "anomaly": {
                        "has_anomaly": cloud_response.anomaly.has_anomaly,
                        "reasons": cloud_response.anomaly.reasons,
                    } if cloud_response.anomaly else None,
                }
                
                # Get dominant chamber
                if cloud_response.chamber_activations:
                    dominant = max(
                        cloud_response.chamber_activations.items(),
                        key=lambda x: x[1]
                    )
                    cloud_data["dominant_chamber"] = dominant[0]
                    cloud_data["dominant_activation"] = dominant[1]
                
            except Exception as e:
                cloud_data = {"error": str(e)}
        
        # ===== 2. UPDATE DSL STATE =====
        dsl_data = {}
        if self.dsl and cloud_response:
            # Map CLOUD chambers to DSL emotional topology
            chambers = cloud_response.chamber_activations
            
            # FEAR + VOID â†’ increases pain
            self.dsl.state.tension = chambers.get("FEAR", 0) * 0.5 + chambers.get("VOID", 0) * 0.3
            
            # RAGE â†’ increases dissonance
            self.dsl.state.dissonance = chambers.get("RAGE", 0) * 0.7
            
            # LOVE â†’ increases resonance
            self.dsl.state.resonance = chambers.get("LOVE", 0) * 0.8 + 0.2
            
            # FLOW + COMPLEX â†’ affects emergence
            self.dsl.state.emergence = (
                chambers.get("FLOW", 0) * 0.5 + 
                chambers.get("COMPLEX", 0) * 0.3
            )
            
            # Compute composite pain
            self.dsl.state.compute_pain()
            
            dsl_data = self.dsl.get_field_metrics()
        
        # ===== 3. HAZE RESPOND =====
        response = await self.haze.respond(user_input)
        
        # ===== 4. TRACK PROPHECY DEBT =====
        if self.dsl:
            # prophecy_debt = |destined - manifested|
            # Here we use resonance as proxy for "how well response matches destiny"
            destined = self.dsl.state.resonance
            manifested = 0.5 + len(response.text) / 500 * 0.3  # longer = more manifested
            self.dsl.update_prophecy_debt(destined, manifested)
        
        # ===== BUILD METADATA =====
        metadata = {
            "internal_seed": response.internal_seed,
            "temperature": response.temperature,
            "generation_time": f"{response.generation_time:.3f}s",
            "turn_count": self.haze.turn_count,
            "enrichment": response.enrichment_count,
        }
        
        if cloud_data:
            metadata["cloud"] = cloud_data
        
        if dsl_data:
            metadata["dsl"] = dsl_data
            metadata["prophecy_debt"] = self.dsl.state.prophecy_debt
            metadata["pain"] = self.dsl.state.pain
        
        if response.trauma:
            metadata["trauma_level"] = response.trauma.level
            metadata["trauma_triggers"] = list(response.trauma.trigger_words)[:5]
        
        if response.trauma_influence:
            metadata["trauma_influence"] = {
                "temp_modifier": response.trauma_influence.temperature_modifier,
                "identity_weight": response.trauma_influence.identity_weight,
                "should_prefix": response.trauma_influence.should_prefix,
            }
        
        if response.expert_mixture:
            metadata["experts"] = response.expert_mixture
        
        if response.pulse:
            metadata["pulse"] = {
                "novelty": response.pulse.novelty,
                "arousal": response.pulse.arousal,
                "entropy": response.pulse.entropy,
            }
        
        # Update history
        self.history.append((user_input, response.text))
        
        return response.text, metadata
    
    def get_cloud_summary(self) -> dict:
        """Get summary of CLOUD activity across session."""
        if not self._cloud_responses:
            return {}
        
        # Count primary emotions
        primary_counts = {}
        for r in self._cloud_responses:
            primary_counts[r.primary] = primary_counts.get(r.primary, 0) + 1
        
        # Average chamber activations
        avg_chambers = {}
        for r in self._cloud_responses:
            for chamber, value in r.chamber_activations.items():
                if chamber not in avg_chambers:
                    avg_chambers[chamber] = []
                avg_chambers[chamber].append(value)
        
        avg_chambers = {k: sum(v)/len(v) for k, v in avg_chambers.items()}
        
        return {
            "total_pings": len(self._cloud_responses),
            "primary_counts": primary_counts,
            "avg_chambers": avg_chambers,
        }
    
    async def close(self):
        """Cleanup."""
        if self.haze:
            await self.haze.__aexit__(None, None, None)
            self.haze = None
        self._initialized = False


# ============================================================================
# GRADIO INTERFACE
# ============================================================================

_session: Optional[HazeSession] = None


def get_session() -> HazeSession:
    """Get or create global session."""
    global _session
    if _session is None:
        _session = HazeSession()
    return _session


async def async_respond(
    message: str,
    history: List[Tuple[str, str]],
) -> Tuple[str, str]:
    """
    Async handler for Gradio.
    """
    session = get_session()
    
    try:
        response_text, metadata = await session.respond(message)
        
        # Format metadata for display
        meta_lines = []
        
        # CLOUD info
        if "cloud" in metadata:
            cloud = metadata["cloud"]
            if "primary" in cloud:
                meta_lines.append(f"ðŸ’­ {cloud['primary']}")
            if "dominant_chamber" in cloud:
                meta_lines.append(f"ðŸ›ï¸ {cloud['dominant_chamber']}")
        
        # Temperature and timing
        if "temperature" in metadata:
            meta_lines.append(f"ðŸŒ¡ï¸ {metadata['temperature']:.2f}")
        meta_lines.append(f"â±ï¸ {metadata.get('generation_time', 'N/A')}")
        
        # DSL state
        if "pain" in metadata:
            meta_lines.append(f"ðŸ’” pain:{metadata['pain']:.2f}")
        if "prophecy_debt" in metadata:
            meta_lines.append(f"ðŸ“œ debt:{metadata['prophecy_debt']:.2f}")
        
        # Trauma
        if "trauma_level" in metadata:
            meta_lines.append(f"ðŸ©¹ trauma:{metadata['trauma_level']:.2f}")
        
        # Turn count
        meta_lines.append(f"ðŸ”„ turn:{metadata.get('turn_count', 0)}")
        
        metadata_str = " | ".join(meta_lines)
        
        return response_text, metadata_str
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"[error] {str(e)}", ""


def respond(
    message: str,
    history: List[Tuple[str, str]],
) -> Tuple[str, str]:
    """Sync wrapper for Gradio."""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(async_respond(message, history))
    finally:
        loop.close()


def create_interface():
    """Create Gradio interface."""
    try:
        import gradio as gr
    except ImportError:
        print("[error] gradio not installed. Run: pip install gradio")
        return None
    
    # Custom CSS for dark gothic theme
    custom_css = """
    .gradio-container {
        background-color: #0a0a0c !important;
    }
    .chatbot .message {
        font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Code', monospace !important;
    }
    """
    
    # ASCII art logo
    logo = """
```
â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•”â•â•â•  
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•
```
**Hybrid Attention Entropy System** + **CLOUD** (~181K params)

*"emergence is not creation but recognition"*

**NO SEED FROM PROMPT** â€” Haze speaks from its internal field, not your input.
    """
    
    with gr.Blocks(css=custom_css, title="HAZE + CLOUD") as demo:
        gr.Markdown(logo)
        
        with gr.Row():
            with gr.Column(scale=3):
                chatbot = gr.Chatbot(
                    label="Conversation",
                    height=450,
                    show_label=False,
                )
                
                with gr.Row():
                    msg = gr.Textbox(
                        label="Your message",
                        placeholder="Speak to the field...",
                        show_label=False,
                        container=False,
                        scale=9,
                    )
                    submit = gr.Button("â†’", scale=1, variant="primary")
                
                metadata_display = gr.Textbox(
                    label="Field State",
                    interactive=False,
                    show_label=True,
                    max_lines=2,
                )
            
            with gr.Column(scale=1):
                gr.Markdown("""
### Architecture

**CLOUD** (~181K params):
- 6 Chambers: FEAR, LOVE, RAGE, VOID, FLOW, COMPLEX
- Cross-fire stabilization
- Meta-observer (secondary emotion)

**HAZE** (emergent field):
- Subjectivity (NO SEED FROM PROMPT)
- Trauma module (identity)
- Expert mixture (4 temperatures)
- Co-occurrence field

**DSL** (Arianna Method):
- prophecy_debt: |destined - manifested|
- pain, tension, dissonance

### Philosophy

> *"presence > intelligence"*
> 
> *"prophecy â‰  prediction"*
> 
> *"minimize(destined - manifested)"*
                """)
        
        def chat(message, history):
            response, metadata = respond(message, history)
            history = history + [(message, response)]
            return "", history, metadata
        
        msg.submit(chat, [msg, chatbot], [msg, chatbot, metadata_display])
        submit.click(chat, [msg, chatbot], [msg, chatbot, metadata_display])
        
        gr.Markdown("""
---
**Part of the Arianna Method** | [GitHub](https://github.com/ariannamethod/haze) | [Leo](https://github.com/ariannamethod/leo) | [PITOMADOM](https://github.com/ariannamethod/pitomadom)

*Co-authored by Claude (GitHub Copilot Coding Agent), January 2026*
        """)
    
    return demo


# ============================================================================
# MAIN
# ============================================================================

def main():
    """Run the Gradio app."""
    print()
    print("=" * 60)
    print("  HAZE â€” Hybrid Attention Entropy System")
    print("  + CLOUD (~181K params)")
    print("  HuggingFace Spaces App")
    print("=" * 60)
    print()
    
    demo = create_interface()
    
    if demo is None:
        print("[error] Could not create interface")
        return
    
    print("Starting Gradio server...")
    print()
    
    # Launch with HuggingFace Spaces compatible settings
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
    )


if __name__ == "__main__":
    main()
